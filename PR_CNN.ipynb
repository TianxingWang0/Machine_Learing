{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions<br>\n",
    "\n",
    "**Based on the MNIST dataset, design and implement a proper convolutional neural network.**<br>\n",
    "**Based on CNN classifiers, please implement an object detection task (including face recognition).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1)Based on the MNIST dataset, design and implement a proper convolutional neural network.<br>\n",
    "    LeNet-5 CNN for handwrite digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the input to fit LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding the images by 2 pixels since in the paper input images were 32x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.pad(X_train, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "X_test = np.pad(X_test, ((0,0),(2,2),(2,2),(0,0)), 'constant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)\n",
    "X_train = (X_train - mean_px)/(std_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "network1 = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer 1: Conv Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1.add(Conv2D(filters = 6,\n",
    "                 kernel_size = 5,\n",
    "                 strides = 1,\n",
    "                 activation = 'relu',\n",
    "                 input_shape = (32, 32, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooling layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1.add(MaxPooling2D(pool_size = 2, strides = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer 2: Conv Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1.add(Conv2D(filters = 16, \n",
    "                 kernel_size = 5,\n",
    "                 strides = 1,\n",
    "                 activation = 'relu',\n",
    "                 input_shape = (14,14,6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooling Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1.add(MaxPooling2D(pool_size = 2, strides = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer 3: Fully connected layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1.add(Dense(units = 120, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer 4: Fully connected layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1.add(Dense(units = 84, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer 5: Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1.add(Dense(units = 10, activation = 'softmax'))\n",
    "network1.compile(optimizer = 'adam', loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train network1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 480s 8ms/step - loss: 0.2299 - acc: 0.9317\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 450s 8ms/step - loss: 0.0671 - acc: 0.9790\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 448s 7ms/step - loss: 0.0468 - acc: 0.9848\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 447s 7ms/step - loss: 0.0367 - acc: 0.9883\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 455s 8ms/step - loss: 0.0318 - acc: 0.9893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2381fbcb240>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network1.fit(X_train ,y_train, batch_size=128, epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test network1 with dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 476us/step\n",
      "test_acc of network1:  0.9774\n"
     ]
    }
   ],
   "source": [
    "test_loss1, test_acc1 = network1.evaluate(X_test, y_test)\n",
    "print('test_acc of network1: ', test_acc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2)Based on CNN classifiers, please implement an object detection task (including face recognition).\n",
    "I implement a face recognition network, tested it with data `olivettifaces.gif`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_load_data(dataset_path):\n",
    "    img = Image.open(dataset_path)\n",
    "    img_ndarray = np.asarray(img, dtype = 'float64')/255\n",
    "    # 400 pictures, size: 57*47 = 2679  \n",
    "    faces_data = np.empty((400, 2679))\n",
    "    for row in range(20):  \n",
    "       for column in range(20):\n",
    "           faces_data[row*20+column] = np.ndarray.flatten(img_ndarray[row*57:(row+1)*57, column*47:(column+1)*47])\n",
    "    label = np.empty(400)\n",
    "    for i in range(40):\n",
    "        label[i*10:(i+1)*10] = i\n",
    "    label = label.astype(np.int)\n",
    "\n",
    "    train_data = np.empty((320, 2679))\n",
    "    train_label = np.empty(320)\n",
    "    valid_data = np.empty((40, 2679))\n",
    "    valid_label = np.empty(40)\n",
    "    test_data = np.empty((40, 2679))\n",
    "    test_label = np.empty(40)\n",
    "    for i in range(40):\n",
    "        train_data[i*8:i*8+8] = faces_data[i*10:i*10+8] \n",
    "        train_label[i*8:i*8+8] = label[i*10 : i*10+8] \n",
    "        valid_data[i] = faces_data[i*10+8]   \n",
    "        valid_label[i] = label[i*10+8]       \n",
    "        test_data[i] = faces_data[i*10+9]   \n",
    "        test_label[i] = label[i*10+9]       \n",
    "    train_data = train_data.astype('float32')\n",
    "    valid_data = valid_data.astype('float32')\n",
    "    test_data = test_data.astype('float32')\n",
    "\n",
    "    result = [(train_data, train_label), (valid_data, valid_label), (test_data, test_label)]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set_model(lr=0.005,decay=1e-6,momentum=0.9):\n",
    "    model = Sequential()\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        model.add(Conv2D(nb_filters1, kernel_size=(3, 3), input_shape = (1, img_rows, img_cols)))\n",
    "    else:\n",
    "        model.add(Conv2D(nb_filters1, kernel_size=(2, 2), input_shape = (img_rows, img_cols, 1)))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(nb_filters2, kernel_size=(3, 3)))\n",
    "    model.add(Activation('tanh'))  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))  \n",
    "\n",
    "    model.add(Flatten())  \n",
    "    model.add(Dense(1000))       #Full connection\n",
    "    model.add(Activation('tanh'))  \n",
    "    model.add(Dropout(0.5))  \n",
    "    model.add(Dense(40))\n",
    "    model.add(Activation('softmax'))  \n",
    "\n",
    "    sgd = SGD(lr=lr, decay=decay, momentum=momentum, nesterov=True)  \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_model(model,X_train, Y_train, X_val, Y_val):\n",
    "    model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs,  \n",
    "          verbose=1, validation_data=(X_val, Y_val))\n",
    "\n",
    "    model.save_weights('model_weights.h5', overwrite=True)  \n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_model(model,X,Y):\n",
    "    model.load_weights('model_weights.h5')  \n",
    "    score = model.evaluate(X, Y, verbose=0)\n",
    "    return score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [start]\n",
    "epochs = 35          \n",
    "batch_size = 40     \n",
    "img_rows, img_cols = 57, 47         \n",
    "nb_filters1, nb_filters2 = 20, 40  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (320, 57, 47, 1)\n",
      "Train on 320 samples, validate on 40 samples\n",
      "Epoch 1/35\n",
      "320/320 [==============================] - 18s 56ms/step - loss: 3.7524 - val_loss: 3.6542\n",
      "Epoch 2/35\n",
      "320/320 [==============================] - 8s 26ms/step - loss: 3.6778 - val_loss: 3.6160\n",
      "Epoch 3/35\n",
      "320/320 [==============================] - 8s 26ms/step - loss: 3.6152 - val_loss: 3.5728\n",
      "Epoch 4/35\n",
      "320/320 [==============================] - 8s 25ms/step - loss: 3.5586 - val_loss: 3.5024\n",
      "Epoch 5/35\n",
      "320/320 [==============================] - 7s 23ms/step - loss: 3.4705 - val_loss: 3.3900\n",
      "Epoch 6/35\n",
      "320/320 [==============================] - 7s 23ms/step - loss: 3.3217 - val_loss: 3.2083\n",
      "Epoch 7/35\n",
      "320/320 [==============================] - 7s 23ms/step - loss: 3.0902 - val_loss: 2.9020\n",
      "Epoch 8/35\n",
      "320/320 [==============================] - 7s 23ms/step - loss: 2.6437 - val_loss: 2.4072\n",
      "Epoch 9/35\n",
      "320/320 [==============================] - 8s 25ms/step - loss: 2.1049 - val_loss: 1.7928\n",
      "Epoch 10/35\n",
      "320/320 [==============================] - 8s 24ms/step - loss: 1.5348 - val_loss: 1.2632\n",
      "Epoch 11/35\n",
      "320/320 [==============================] - 8s 24ms/step - loss: 0.9965 - val_loss: 0.9016\n",
      "Epoch 12/35\n",
      "320/320 [==============================] - 7s 22ms/step - loss: 0.6843 - val_loss: 0.6438\n",
      "Epoch 13/35\n",
      "320/320 [==============================] - 7s 22ms/step - loss: 0.4893 - val_loss: 0.5082\n",
      "Epoch 14/35\n",
      "320/320 [==============================] - 7s 23ms/step - loss: 0.3373 - val_loss: 0.4512\n",
      "Epoch 15/35\n",
      "320/320 [==============================] - 7s 22ms/step - loss: 0.2835 - val_loss: 0.3885\n",
      "Epoch 16/35\n",
      "320/320 [==============================] - 8s 25ms/step - loss: 0.2235 - val_loss: 0.3439\n",
      "Epoch 17/35\n",
      "320/320 [==============================] - 7s 21ms/step - loss: 0.1658 - val_loss: 0.2950\n",
      "Epoch 18/35\n",
      "320/320 [==============================] - 7s 22ms/step - loss: 0.1560 - val_loss: 0.2625\n",
      "Epoch 19/35\n",
      "320/320 [==============================] - 7s 23ms/step - loss: 0.1230 - val_loss: 0.2458\n",
      "Epoch 20/35\n",
      "320/320 [==============================] - 8s 26ms/step - loss: 0.1077 - val_loss: 0.2254\n",
      "Epoch 21/35\n",
      "320/320 [==============================] - 8s 25ms/step - loss: 0.0920 - val_loss: 0.2112\n",
      "Epoch 22/35\n",
      "320/320 [==============================] - 8s 24ms/step - loss: 0.0782 - val_loss: 0.1934\n",
      "Epoch 23/35\n",
      "320/320 [==============================] - 8s 26ms/step - loss: 0.0719 - val_loss: 0.1863\n",
      "Epoch 24/35\n",
      "320/320 [==============================] - 9s 27ms/step - loss: 0.0701 - val_loss: 0.1850\n",
      "Epoch 25/35\n",
      "320/320 [==============================] - 8s 24ms/step - loss: 0.0623 - val_loss: 0.1770\n",
      "Epoch 26/35\n",
      "320/320 [==============================] - 8s 24ms/step - loss: 0.0647 - val_loss: 0.1722\n",
      "Epoch 27/35\n",
      "320/320 [==============================] - 8s 24ms/step - loss: 0.0618 - val_loss: 0.1696\n",
      "Epoch 28/35\n",
      "320/320 [==============================] - 8s 26ms/step - loss: 0.0499 - val_loss: 0.1611\n",
      "Epoch 29/35\n",
      "320/320 [==============================] - 8s 26ms/step - loss: 0.0464 - val_loss: 0.1499\n",
      "Epoch 30/35\n",
      "320/320 [==============================] - 7s 22ms/step - loss: 0.0457 - val_loss: 0.1471\n",
      "Epoch 31/35\n",
      "320/320 [==============================] - 7s 23ms/step - loss: 0.0357 - val_loss: 0.1485\n",
      "Epoch 32/35\n",
      "320/320 [==============================] - 8s 26ms/step - loss: 0.0407 - val_loss: 0.1518\n",
      "Epoch 33/35\n",
      "320/320 [==============================] - 8s 24ms/step - loss: 0.0405 - val_loss: 0.1488\n",
      "Epoch 34/35\n",
      "320/320 [==============================] - 7s 22ms/step - loss: 0.0408 - val_loss: 0.1475\n",
      "Epoch 35/35\n",
      "320/320 [==============================] - 8s 26ms/step - loss: 0.0322 - val_loss: 0.1468\n",
      "last accuarcy: 0.975\n",
      "18.0 be misclassified as:  14\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_val, y_val),(X_test, y_test) = get_load_data('C:/Users/28347/olivettifaces.gif')\n",
    "\n",
    "if K.image_data_format() == 'channels_first':    \n",
    "    X_train = X_train.reshape(X_train.shape[0],1,img_rows,img_cols)\n",
    "    X_val = X_val.reshape(X_val.shape[0], 1, img_rows, img_cols)  \n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)  \n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)  \n",
    "    X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)  \n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)  \n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "# convert class vectors to binary class matrices  \n",
    "Y_train = np_utils.to_categorical(y_train, 40)\n",
    "Y_val = np_utils.to_categorical(y_val, 40)\n",
    "Y_test = np_utils.to_categorical(y_test, 40)\n",
    "\n",
    "model = get_set_model()\n",
    "get_train_model(model, X_train, Y_train, X_val, Y_val)\n",
    "score = get_test_model(model, X_test, Y_test)\n",
    "\n",
    "model.load_weights('model_weights.h5')\n",
    "classes = model.predict_classes(X_test, verbose=0)  \n",
    "test_accuracy = np.mean(np.equal(y_test, classes))\n",
    "print(\"last accuarcy:\", test_accuracy)\n",
    "for i in range(0,40):\n",
    "    if y_test[i] != classes[i]:\n",
    "        print(y_test[i], 'be misclassified as: ', classes[i]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
